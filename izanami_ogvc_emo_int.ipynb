{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitani/.conda/envs/ser/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ogvc_izanami_features.csv\n"
     ]
    }
   ],
   "source": [
    "# OGVC\n",
    "# 産総研のizanamiで使用されているwav2vec2の出力をogvc_izanami_features.csvに保存\n",
    "# wav2vec2_vad_ogvc.ipynbとの比較, カーネル；ser\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "# 設定\n",
    "# ===============================\n",
    "ROOT_WAV_DIR = \"/autofs/diamond2/share/diamond/corpus/OGVC/Vol2/Acted/wav\"\n",
    "MODEL_NAME = \"imprt/izanami-wav2vec2-large\"\n",
    "OUTPUT_CSV = \"ogvc_izanami_features.csv\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===============================\n",
    "# モデルロード\n",
    "# ===============================\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ===============================\n",
    "# ファイル名解析用 regex\n",
    "# FOY0101ANT0.wav → emotion=ANT, intensity=0\n",
    "# ===============================\n",
    "FILENAME_PATTERN = re.compile(r\"^[A-Z0-9]+([A-Z]{3})(\\d)\\.wav$\")\n",
    "\n",
    "# ===============================\n",
    "# CSV ヘッダ作成\n",
    "# ===============================\n",
    "rows = []\n",
    "header_written = False\n",
    "\n",
    "# ===============================\n",
    "# wav 以下を再帰探索\n",
    "# ===============================\n",
    "for root, _, files in os.walk(ROOT_WAV_DIR):\n",
    "    for fname in files:\n",
    "        if not fname.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "\n",
    "        match = FILENAME_PATTERN.match(fname)\n",
    "        if match is None:\n",
    "            print(f\"Skip (filename mismatch): {fname}\")\n",
    "            continue\n",
    "\n",
    "        emotion = match.group(1)\n",
    "        intensity = int(match.group(2))\n",
    "        wav_path = os.path.join(root, fname)\n",
    "\n",
    "        # ===============================\n",
    "        # 音声ロード & リサンプリング\n",
    "        # ===============================\n",
    "        audio, sr = sf.read(wav_path)\n",
    "\n",
    "        # stereo → mono\n",
    "        if audio.ndim > 1:\n",
    "            audio = audio.mean(axis=1)\n",
    "\n",
    "        # resample to 16kHz（←ここが重要）\n",
    "        if sr != 16000:\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "            sr = 16000\n",
    "\n",
    "        # ===============================\n",
    "        # 特徴量抽出\n",
    "        # ===============================\n",
    "        inputs = feature_extractor(\n",
    "            audio,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            hidden_states = outputs.last_hidden_state  # (T, D) or (1, T, D)\n",
    "\n",
    "        # (1, T, D) → (T, D)\n",
    "        hidden_states = hidden_states.squeeze(0)\n",
    "\n",
    "        # ===============================\n",
    "        # 時間方向 mean pooling\n",
    "        # ===============================\n",
    "        feature_vector = hidden_states.mean(dim=0).cpu().numpy()  # (D,)\n",
    "\n",
    "        # ===============================\n",
    "        # CSV 用 row 作成\n",
    "        # ===============================\n",
    "        row = [fname, emotion, intensity] + feature_vector.tolist()\n",
    "        rows.append(row)\n",
    "\n",
    "        # ヘッダは最初の1回だけ作る\n",
    "        if not header_written:\n",
    "            header = (\n",
    "                [\"filename\", \"emotion\", \"intensity\"]\n",
    "                + [f\"ssl_{i}\" for i in range(len(feature_vector))]\n",
    "            )\n",
    "            header_written = True\n",
    "\n",
    "# ===============================\n",
    "# CSV 書き込み\n",
    "# ===============================\n",
    "with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6cd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "          filename emotion  intensity    ssl_0     ssl_1     ssl_2     ssl_3  \\\n",
      "0  FOY0806ANG2.wav     ANG          2  0.00653 -0.107648 -0.213318 -0.308118   \n",
      "1  FOY0101ANT2.wav     ANT          2  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "2  FOY0101ANT3.wav     ANT          3  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "3  FOY0104FEA0.wav     FEA          0  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "4  FOY0104FEA3.wav     FEA          3  0.00653 -0.107648 -0.213318 -0.308118   \n",
      "\n",
      "      ssl_4     ssl_5     ssl_6  ...  ssl_1014  ssl_1015  ssl_1016  ssl_1017  \\\n",
      "0 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "1 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "2 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "3 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "4 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "\n",
      "   ssl_1018  ssl_1019  ssl_1020  ssl_1021  ssl_1022  ssl_1023  \n",
      "0  0.147275  0.169446 -0.200256 -1.461907 -0.325677 -0.064124  \n",
      "1  0.147275  0.169446 -0.200256 -1.461902 -0.325677 -0.064124  \n",
      "2  0.147275  0.169446 -0.200256 -1.461903 -0.325677 -0.064124  \n",
      "3  0.147275  0.169446 -0.200256 -1.461905 -0.325677 -0.064124  \n",
      "4  0.147275  0.169446 -0.200256 -1.461909 -0.325677 -0.064124  \n",
      "\n",
      "[5 rows x 1027 columns]\n",
      "\n",
      "=== Step3: 評価 ===\n",
      "\n",
      "Emotion Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.13      0.14        67\n",
      "           1       0.18      0.23      0.21        64\n",
      "           2       0.13      0.12      0.13        64\n",
      "           3       0.26      0.23      0.25        77\n",
      "           4       0.13      0.15      0.14        68\n",
      "           5       0.22      0.20      0.21        64\n",
      "           6       0.18      0.20      0.19        64\n",
      "           7       0.24      0.20      0.22        64\n",
      "\n",
      "    accuracy                           0.19       532\n",
      "   macro avg       0.19      0.19      0.19       532\n",
      "weighted avg       0.19      0.19      0.19       532\n",
      "\n",
      "\n",
      "Intensity Regression Metrics\n",
      "MAE : 1.0229\n",
      "RMSE: 1.2662\n",
      "\n",
      "予測結果を保存しました → results_ogvc_emo_int-izanami/prediction_results.csv\n",
      "混同行列保存 → results_ogvc_emo_int-izanami/confusion_emotion.png\n",
      "\n",
      "=== 完了：Step1 → Step2 → Step3 ===\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# OGVC 版：sklearnで Emotion→分類/intensity→回帰\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge              # 強度用の回帰\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int-izanami\"     # 結果\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# Step2: データ分割 & モデル学習\n",
    "# =========================================================\n",
    "def step2_train_model(df):\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression, Ridge\n",
    "    import os\n",
    "\n",
    "    SPLIT_DIR = \"ogvc_split_data-izanami\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 特徴量とラベル\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int = df[\"intensity\"]\n",
    "\n",
    "    filename = df[\"filename\"]\n",
    "\n",
    "    # 分割\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test, filename_train, filename_test = train_test_split(\n",
    "        X, y_emo, y_int, filename, test_size=0.2, random_state=42, stratify=y_emo\n",
    "    )\n",
    "\n",
    "    # === ここが本質 ===\n",
    "    X_train_np = X_train.to_numpy(dtype=np.float32)\n",
    "    X_test_np  = X_test.to_numpy(dtype=np.float32)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_np = scaler.fit_transform(X_train_np)\n",
    "    X_test_np  = scaler.transform(X_test_np)\n",
    "\n",
    "    # 学習\n",
    "    emo_model = LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\"\n",
    "    ).fit(X_train_np, emo_train)\n",
    "\n",
    "    int_model = Ridge().fit(X_train_np, int_train)\n",
    "\n",
    "    return {\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model,\n",
    "        \"X_test\": X_test_np,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"filename_test\": filename_test.values,\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# Step3: 評価 & CSV出力\n",
    "# =========================================================\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Step3: 評価 ===\")\n",
    "\n",
    "    # ===== 感情（分類）=====\n",
    "    print(\"\\nEmotion Classification Report\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "\n",
    "    # ===== 強度（回帰）=====\n",
    "    mae = mean_absolute_error(int_test, int_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(int_test, int_pred))\n",
    "\n",
    "    print(\"\\nIntensity Regression Metrics\")\n",
    "    print(f\"MAE : {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "    # ===== CSV 保存 =====\n",
    "    emotion_correct = [\"〇\" if t == p else \"×\" for t, p in zip(emo_test, emo_pred)]\n",
    "    intensity_error = np.abs(int_test - int_pred)\n",
    "\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"emotion_correct\": emotion_correct,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"intensity_abs_error\": intensity_error\n",
    "    })\n",
    "\n",
    "    pred_path = os.path.join(RESULT_DIR, \"prediction_results.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"\\n予測結果を保存しました →\", pred_path)\n",
    "\n",
    "    # ===== 混同行列（感情のみ）=====\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion.png\")\n",
    "\n",
    "    plot_conf_matrix(\n",
    "        emo_test,\n",
    "        emo_pred,\n",
    "        list(EMOTION_LABELS.keys()),\n",
    "        \"OGVC Emotion Confusion Matrix\",\n",
    "        emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "\n",
    "    print(\"混同行列保存 →\", emo_cm_path)\n",
    "\n",
    "# =========================================================\n",
    "# 実行部\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"ogvc_izanami_features.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Step1 → Step2 → Step3 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdb8690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved emotion-labeled results to: results_ogvc_emo_int-izanami/pred_results_with_emotion_label.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の感情を数値からラベルに変換\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int-izanami\"\n",
    "pred_path = os.path.join(RESULT_DIR, \"prediction_results.csv\")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 感情ラベル対応表\n",
    "# ================================\n",
    "EMOTION_ID2LABEL = {\n",
    "    0: \"JOY\",\n",
    "    1: \"ACC\",\n",
    "    2: \"FEA\",\n",
    "    3: \"SUR\",\n",
    "    4: \"SAD\",\n",
    "    5: \"DIS\",\n",
    "    6: \"ANG\",\n",
    "    7: \"ANT\"\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(pred_path)\n",
    "\n",
    "# ================================\n",
    "# 感情カテゴリのみラベル化\n",
    "# ================================\n",
    "df[\"emotion_true_label\"] = df[\"emotion_true\"].map(EMOTION_ID2LABEL)\n",
    "df[\"emotion_pred_label\"] = df[\"emotion_pred\"].map(EMOTION_ID2LABEL)\n",
    "\n",
    "# ※ intensity_true / intensity_pred はそのまま残す\n",
    "\n",
    "# ================================\n",
    "# 保存\n",
    "# ================================\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved emotion-labeled results to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fff951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Intensity Performance ===\n",
      "MAE  : 1.0229\n",
      "RMSE : 1.2662\n",
      "\n",
      "=== Emotion-wise Intensity Performance ===\n",
      "  emotion_true_label       MAE      RMSE  Count\n",
      "0                ACC  1.101547  1.371877     64\n",
      "1                ANG  0.972356  1.176386     64\n",
      "2                ANT  1.247847  1.576385     64\n",
      "3                DIS  1.080584  1.341359     64\n",
      "4                FEA  0.936044  1.109407     64\n",
      "5                JOY  0.908127  1.120762     67\n",
      "6                SAD  1.112807  1.299792     68\n",
      "7                SUR  0.857064  1.092550     77\n",
      "\n",
      "Saved to: results_ogvc_emo_int-izanami/eval_emotion_wise_intensity_mae_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果(pred_results_with_emotion_label.csv)を読み込んで，全体＋感情別 MAE / RMSEを出力\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int-izanami\"\n",
    "csv_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label.csv\"\n",
    ")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"eval_emotion_wise_intensity_mae_rmse.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ================================\n",
    "# 誤差計算（RMSE用）\n",
    "# ================================\n",
    "signed_error = df[\"intensity_pred\"] - df[\"intensity_true\"]\n",
    "df[\"sq_error\"] = signed_error ** 2\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ モデル全体 MAE / RMSE\n",
    "# ================================\n",
    "overall_mae = df[\"intensity_abs_error\"].mean()\n",
    "overall_rmse = np.sqrt(df[\"sq_error\"].mean())\n",
    "\n",
    "print(\"=== Overall Intensity Performance ===\")\n",
    "print(f\"MAE  : {overall_mae:.4f}\")\n",
    "print(f\"RMSE : {overall_rmse:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ 感情カテゴリ別 MAE / RMSE\n",
    "# ================================\n",
    "emotion_metrics = (\n",
    "    df.groupby(\"emotion_true_label\")\n",
    "      .agg(\n",
    "          MAE=(\"intensity_abs_error\", \"mean\"),\n",
    "          RMSE=(\"sq_error\", lambda x: np.sqrt(x.mean())),\n",
    "          Count=(\"filename\", \"count\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Emotion-wise Intensity Performance ===\")\n",
    "print(emotion_metrics)\n",
    "\n",
    "# ================================\n",
    "# 保存\n",
    "# ================================\n",
    "emotion_metrics.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5359f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "          filename emotion  intensity    ssl_0     ssl_1     ssl_2     ssl_3  \\\n",
      "0  FOY0806ANG2.wav     ANG          2  0.00653 -0.107648 -0.213318 -0.308118   \n",
      "1  FOY0101ANT2.wav     ANT          2  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "2  FOY0101ANT3.wav     ANT          3  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "3  FOY0104FEA0.wav     FEA          0  0.00653 -0.107648 -0.213318 -0.308119   \n",
      "4  FOY0104FEA3.wav     FEA          3  0.00653 -0.107648 -0.213318 -0.308118   \n",
      "\n",
      "      ssl_4     ssl_5     ssl_6  ...  ssl_1014  ssl_1015  ssl_1016  ssl_1017  \\\n",
      "0 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "1 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "2 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "3 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "4 -0.065852 -0.095156 -0.152033  ... -0.239009  0.015603 -0.278374 -0.082475   \n",
      "\n",
      "   ssl_1018  ssl_1019  ssl_1020  ssl_1021  ssl_1022  ssl_1023  \n",
      "0  0.147275  0.169446 -0.200256 -1.461907 -0.325677 -0.064124  \n",
      "1  0.147275  0.169446 -0.200256 -1.461902 -0.325677 -0.064124  \n",
      "2  0.147275  0.169446 -0.200256 -1.461903 -0.325677 -0.064124  \n",
      "3  0.147275  0.169446 -0.200256 -1.461905 -0.325677 -0.064124  \n",
      "4  0.147275  0.169446 -0.200256 -1.461909 -0.325677 -0.064124  \n",
      "\n",
      "[5 rows x 1027 columns]\n",
      "\n",
      "=== Step3: 評価 ===\n",
      "\n",
      "Emotion Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.13      0.14        67\n",
      "           1       0.18      0.23      0.21        64\n",
      "           2       0.13      0.12      0.13        64\n",
      "           3       0.26      0.23      0.25        77\n",
      "           4       0.13      0.15      0.14        68\n",
      "           5       0.22      0.20      0.21        64\n",
      "           6       0.18      0.20      0.19        64\n",
      "           7       0.24      0.20      0.22        64\n",
      "\n",
      "    accuracy                           0.19       532\n",
      "   macro avg       0.19      0.19      0.19       532\n",
      "weighted avg       0.19      0.19      0.19       532\n",
      "\n",
      "\n",
      "Intensity Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.34      0.34       137\n",
      "           1       0.29      0.29      0.29       138\n",
      "           2       0.34      0.31      0.32       139\n",
      "           3       0.39      0.44      0.41       118\n",
      "\n",
      "    accuracy                           0.34       532\n",
      "   macro avg       0.34      0.34      0.34       532\n",
      "weighted avg       0.34      0.34      0.34       532\n",
      "\n",
      "\n",
      "予測結果を保存しました → results_ogvc_emo_int-izanami-bunrui/prediction_results.csv\n",
      "混同行列保存 → results_ogvc_emo_int-izanami-bunrui/confusion_emotion.png\n",
      "混同行列保存 → results_ogvc_emo_int-izanami-bunrui/confusion_intensity.png\n",
      "\n",
      "=== 完了：Step1 → Step2 → Step3 ===\n"
     ]
    }
   ],
   "source": [
    "# 強度を回帰ではなく分類してみる(番外編)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge              # 強度用の回帰\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int-izanami-bunrui\"     # 結果\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "def step2_train_model(df):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    SPLIT_DIR = \"ogvc_split_data-izanami\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 特徴量\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    # ラベル\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int_cls = df[\"intensity\"].astype(int)   # ★ 分類なので int\n",
    "\n",
    "    filename = df[\"filename\"]\n",
    "\n",
    "    # 分割\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test, filename_train, filename_test = train_test_split(\n",
    "        X, y_emo, y_int_cls, filename,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_emo\n",
    "    )\n",
    "\n",
    "    # numpy 化 + 標準化\n",
    "    X_train_np = X_train.to_numpy(dtype=np.float32)\n",
    "    X_test_np  = X_test.to_numpy(dtype=np.float32)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_np = scaler.fit_transform(X_train_np)\n",
    "    X_test_np  = scaler.transform(X_test_np)\n",
    "\n",
    "    # ===== モデル学習 =====\n",
    "    emo_model = LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\"\n",
    "    ).fit(X_train_np, emo_train)\n",
    "\n",
    "    int_model = LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\"\n",
    "    ).fit(X_train_np, int_train)\n",
    "\n",
    "    return {\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model,\n",
    "        \"X_test\": X_test_np,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"filename_test\": filename_test.values,\n",
    "    }\n",
    "\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Step3: 評価 ===\")\n",
    "\n",
    "    # ===== 感情 =====\n",
    "    print(\"\\nEmotion Classification Report\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "\n",
    "    # ===== 強度（分類）=====\n",
    "    print(\"\\nIntensity Classification Report\")\n",
    "    print(classification_report(int_test, int_pred))\n",
    "\n",
    "    # ===== CSV 保存 =====\n",
    "    emotion_correct = [\"〇\" if t == p else \"×\" for t, p in zip(emo_test, emo_pred)]\n",
    "    intensity_correct = [\"〇\" if t == p else \"×\" for t, p in zip(int_test, int_pred)]\n",
    "\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"emotion_correct\": emotion_correct,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"intensity_correct\": intensity_correct\n",
    "    })\n",
    "\n",
    "    pred_path = os.path.join(RESULT_DIR, \"prediction_results.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"\\n予測結果を保存しました →\", pred_path)\n",
    "\n",
    "    # ===== 混同行列 =====\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion.png\")\n",
    "    int_cm_path = os.path.join(RESULT_DIR, \"confusion_intensity.png\")\n",
    "\n",
    "    plot_conf_matrix(\n",
    "        emo_test,\n",
    "        emo_pred,\n",
    "        list(EMOTION_LABELS.keys()),\n",
    "        \"OGVC Emotion Confusion Matrix\",\n",
    "        emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "\n",
    "    plot_conf_matrix(       # 3を追加\n",
    "        int_test,\n",
    "        int_pred,\n",
    "        [\"0\", \"1\", \"2\", \"3\"],\n",
    "        \"OGVC Intensity Classification Confusion Matrix\",\n",
    "        int_cm_path\n",
    "    )\n",
    "\n",
    "    print(\"混同行列保存 →\", emo_cm_path)\n",
    "    print(\"混同行列保存 →\", int_cm_path)\n",
    "\n",
    "# =========================================================\n",
    "# 実行部\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"ogvc_izanami_features.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Step1 → Step2 → Step3 ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
