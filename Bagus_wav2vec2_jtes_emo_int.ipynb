{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71178a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitani/.conda/envs/ser/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mitani/.conda/envs/ser/lib/python3.11/site-packages/transformers/configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at Bagus/wav2vec2-xlsr-japanese-speech-emotion-recognition and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ogvc_wav2vec2_features_Bagus-jtes.csv\n"
     ]
    }
   ],
   "source": [
    "# OGVC\n",
    "# JTESで感情分類にファインチューニングされた日本語感情認識モデルのSSL\n",
    "# wav2vec2-XLSR から音響特徴量を抽出してCSV保存\n",
    "# 実行時のエラーだが、今回は特徴抽出のために分類ヘッドを付けているだけだから、初期化されても問題ない\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "\n",
    "# ===============================\n",
    "# 設定\n",
    "# ===============================\n",
    "ROOT_WAV_DIR = \"/autofs/diamond2/share/diamond/corpus/OGVC/Vol2/Acted/wav\"\n",
    "MODEL_NAME = \"Bagus/wav2vec2-xlsr-japanese-speech-emotion-recognition\"\n",
    "OUTPUT_CSV = \"ogvc_wav2vec2_features_Bagus-jtes.csv\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===============================\n",
    "# モデルロード\n",
    "# ===============================\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    output_hidden_states=True\n",
    ").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "hidden_dim = model.config.hidden_size  # 768\n",
    "\n",
    "# ===============================\n",
    "# ファイル名解析用 regex\n",
    "# FOY0101ANT0.wav → emotion=ANT, intensity=0\n",
    "# ===============================\n",
    "FILENAME_PATTERN = re.compile(r\"^[A-Z0-9]+([A-Z]{3})(\\d)\\.wav$\")\n",
    "\n",
    "# ===============================\n",
    "# CSV ヘッダ管理\n",
    "# ===============================\n",
    "rows = []\n",
    "header_written = False\n",
    "\n",
    "# ===============================\n",
    "# wav 以下を再帰探索\n",
    "# ===============================\n",
    "for root, _, files in os.walk(ROOT_WAV_DIR):\n",
    "    for fname in files:\n",
    "        if not fname.lower().endswith(\".wav\"):\n",
    "            continue\n",
    "\n",
    "        match = FILENAME_PATTERN.match(fname)\n",
    "        if match is None:\n",
    "            print(f\"Skip (filename mismatch): {fname}\")\n",
    "            continue\n",
    "\n",
    "        emotion = match.group(1)\n",
    "        intensity = int(match.group(2))\n",
    "        wav_path = os.path.join(root, fname)\n",
    "\n",
    "        # ===============================\n",
    "        # 音声ロード & リサンプリング\n",
    "        # ===============================\n",
    "        audio, sr = sf.read(wav_path)\n",
    "\n",
    "        # stereo → mono\n",
    "        if audio.ndim > 1:\n",
    "            audio = audio.mean(axis=1)\n",
    "\n",
    "        # resample to 16kHz（wav2vec2前提）\n",
    "        if sr != feature_extractor.sampling_rate:\n",
    "            audio = librosa.resample(\n",
    "                audio,\n",
    "                orig_sr=sr,\n",
    "                target_sr=feature_extractor.sampling_rate\n",
    "            )\n",
    "            sr = feature_extractor.sampling_rate\n",
    "\n",
    "        # ===============================\n",
    "        # 特徴量抽出\n",
    "        # ===============================\n",
    "        inputs = feature_extractor(\n",
    "            audio,\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # ===============================\n",
    "        # 音響特徴量（最終層 hidden states）\n",
    "        # hidden_states[-1]: (1, T, D)\n",
    "        # ===============================\n",
    "        hidden_states = outputs.hidden_states[-1].squeeze(0)  # (T, D)\n",
    "\n",
    "        # ===============================\n",
    "        # 時間方向 mean pooling\n",
    "        # ===============================\n",
    "        feature_vector = hidden_states.mean(dim=0).cpu().numpy()  # (D,)\n",
    "\n",
    "        # ===============================\n",
    "        # CSV 用 row 作成\n",
    "        # ===============================\n",
    "        row = [fname, emotion, intensity] + feature_vector.tolist()\n",
    "        rows.append(row)\n",
    "\n",
    "        # ヘッダは最初の1回だけ作る\n",
    "        if not header_written:\n",
    "            header = (\n",
    "                [\"filename\", \"emotion\", \"intensity\"]\n",
    "                + [f\"ssl_{i}\" for i in range(len(feature_vector))]\n",
    "            )\n",
    "            header_written = True\n",
    "\n",
    "# ===============================\n",
    "# CSV 書き込み\n",
    "# ===============================\n",
    "with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf1c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "          filename emotion  intensity     ssl_0     ssl_1     ssl_2     ssl_3  \\\n",
      "0  FOY0806ANG2.wav     ANG          2 -0.166178 -0.335452  0.283190  0.100455   \n",
      "1  FOY0101ANT2.wav     ANT          2 -0.588002  1.086630  0.672229 -0.049684   \n",
      "2  FOY0101ANT3.wav     ANT          3 -0.590559  0.742118  0.564494  0.044688   \n",
      "3  FOY0104FEA0.wav     FEA          0 -0.559797 -1.040905 -0.112782 -0.069219   \n",
      "4  FOY0104FEA3.wav     FEA          3 -0.176736 -1.262802 -0.658257  0.023738   \n",
      "\n",
      "      ssl_4     ssl_5     ssl_6  ...  ssl_1014  ssl_1015  ssl_1016  ssl_1017  \\\n",
      "0  0.330798 -1.102320  0.444114  ...  0.115072 -0.214865  0.600724 -1.021574   \n",
      "1  0.180771 -0.479517 -0.921932  ... -0.198160 -0.254211  0.479511  0.340814   \n",
      "2  0.119269 -0.664458 -0.651955  ... -0.409490 -0.173947  0.384327  0.221036   \n",
      "3  0.418174 -1.086987  0.788613  ...  0.228670  0.262627  0.718724  0.394348   \n",
      "4 -0.166624 -0.927520  1.510856  ... -0.192233  0.592060  0.744003 -0.399632   \n",
      "\n",
      "   ssl_1018  ssl_1019  ssl_1020  ssl_1021  ssl_1022  ssl_1023  \n",
      "0  1.210417  0.145564 -0.203183  0.308363 -1.006108  0.477833  \n",
      "1  1.386149 -0.865146 -0.025146  0.664296 -0.966043 -0.970576  \n",
      "2  0.895769 -0.774165 -0.138155  0.092459 -1.149930 -0.854394  \n",
      "3  1.105802  0.896047 -0.832068  0.055074 -0.788869  0.787627  \n",
      "4 -0.680709  0.574865 -0.695022  0.356909 -0.324964  0.789080  \n",
      "\n",
      "[5 rows x 1027 columns]\n",
      "=== Step2: モデル学習完了 ===\n",
      "\n",
      "=== Step3: 評価 ===\n",
      "\n",
      "Emotion Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        67\n",
      "           1       0.94      0.91      0.92        64\n",
      "           2       0.97      0.89      0.93        64\n",
      "           3       0.97      0.88      0.93        77\n",
      "           4       0.94      0.97      0.96        68\n",
      "           5       0.85      0.91      0.88        64\n",
      "           6       0.97      0.97      0.97        64\n",
      "           7       0.90      0.97      0.93        64\n",
      "\n",
      "    accuracy                           0.93       532\n",
      "   macro avg       0.93      0.93      0.93       532\n",
      "weighted avg       0.93      0.93      0.93       532\n",
      "\n",
      "\n",
      "Intensity Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       137\n",
      "           1       0.34      0.35      0.34       138\n",
      "           2       0.31      0.28      0.29       139\n",
      "           3       0.53      0.57      0.55       118\n",
      "\n",
      "    accuracy                           0.45       532\n",
      "   macro avg       0.45      0.45      0.45       532\n",
      "weighted avg       0.45      0.45      0.45       532\n",
      "\n",
      "\n",
      "予測結果を保存しました → results_ogvc_emo_int/prediction_results-bagus.csv\n",
      "混同行列保存 → results_ogvc_emo_int/confusion_emotion-bagus.png\n",
      "混同行列保存 → results_ogvc_emo_int/confusion_intensity-bagus.png\n",
      "\n",
      "=== 完了：Step1 → Step2 → Step3 ===\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# OGVC 版：ロジスティック回帰で Emotion / Intensity を分類\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\", annot_kws={\"size\": 16})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# Step2: データ分割 & モデル学習\n",
    "# =========================================================\n",
    "def step2_train_model(df):\n",
    "    SPLIT_DIR = \"ogvc_split_data\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int = df[\"intensity\"]\n",
    "\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test = train_test_split(\n",
    "        X, y_emo, y_int, test_size=0.2, random_state=42, stratify=y_emo\n",
    "    )\n",
    "\n",
    "    train_df = df.loc[X_train.index]\n",
    "    test_df = df.loc[X_test.index]\n",
    "    train_df.to_csv(os.path.join(TRAIN_DIR, \"train_data-bagus.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(TEST_DIR, \"test_data-bagus.csv\"), index=False)\n",
    "\n",
    "    emo_model = LogisticRegression(max_iter=3000).fit(X_train, emo_train)\n",
    "    int_model = LogisticRegression(max_iter=3000).fit(X_train, int_train)\n",
    "\n",
    "    print(\"=== Step2: モデル学習完了 ===\")\n",
    "\n",
    "    return {\n",
    "        \"X_test\": X_test,\n",
    "        \"filename_test\": df.loc[X_test.index, \"filename\"] if \"filename\" in df.columns else None,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# Step3: 評価 & CSV出力\n",
    "# =========================================================\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Step3: 評価 ===\")\n",
    "    print(\"\\nEmotion Classification Report\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "    print(\"\\nIntensity Classification Report\")\n",
    "    print(classification_report(int_test, int_pred))\n",
    "\n",
    "    # 予測結果 CSV 保存\n",
    "    emotion_correct = [\"〇\" if t == p else \"×\" for t, p in zip(emo_test, emo_pred)]\n",
    "    intensity_correct = [\"〇\" if t == p else \"×\" for t, p in zip(int_test, int_pred)]\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"emotion_correct\": emotion_correct,\n",
    "        \"intensity_correct\": intensity_correct\n",
    "    })\n",
    "    pred_path = os.path.join(RESULT_DIR, \"prediction_results-bagus.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"\\n予測結果を保存しました →\", pred_path)\n",
    "\n",
    "    # 混同行列\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion-bagus.png\")\n",
    "    int_cm_path = os.path.join(RESULT_DIR, \"confusion_intensity-bagus.png\")\n",
    "\n",
    "    plot_conf_matrix(\n",
    "        emo_test, emo_pred, list(EMOTION_LABELS.keys()),\n",
    "        \" OGVC Emotion Confusion Matrix\", emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "\n",
    "    plot_conf_matrix(   # 3を追加\n",
    "        int_test, int_pred, [\"0\", \"1\", \"2\", \"3\"],\n",
    "        \"OGVC Intensity Confusion Matrix\", int_cm_path\n",
    "    )\n",
    "\n",
    "    print(\"混同行列保存 →\", emo_cm_path)\n",
    "    print(\"混同行列保存 →\", int_cm_path)\n",
    "\n",
    "# =========================================================\n",
    "# メイン処理\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"ogvc_wav2vec2_features_Bagus-jtes.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Step1 → Step2 → Step3 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7b4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "          filename emotion  intensity     ssl_0     ssl_1     ssl_2     ssl_3  \\\n",
      "0  FOY0806ANG2.wav     ANG          2 -0.166178 -0.335452  0.283190  0.100455   \n",
      "1  FOY0101ANT2.wav     ANT          2 -0.588002  1.086630  0.672229 -0.049684   \n",
      "2  FOY0101ANT3.wav     ANT          3 -0.590559  0.742118  0.564494  0.044688   \n",
      "3  FOY0104FEA0.wav     FEA          0 -0.559797 -1.040905 -0.112782 -0.069219   \n",
      "4  FOY0104FEA3.wav     FEA          3 -0.176736 -1.262802 -0.658257  0.023738   \n",
      "\n",
      "      ssl_4     ssl_5     ssl_6  ...  ssl_1014  ssl_1015  ssl_1016  ssl_1017  \\\n",
      "0  0.330798 -1.102320  0.444114  ...  0.115072 -0.214865  0.600724 -1.021574   \n",
      "1  0.180771 -0.479517 -0.921932  ... -0.198160 -0.254211  0.479511  0.340814   \n",
      "2  0.119269 -0.664458 -0.651955  ... -0.409490 -0.173947  0.384327  0.221036   \n",
      "3  0.418174 -1.086987  0.788613  ...  0.228670  0.262627  0.718724  0.394348   \n",
      "4 -0.166624 -0.927520  1.510856  ... -0.192233  0.592060  0.744003 -0.399632   \n",
      "\n",
      "   ssl_1018  ssl_1019  ssl_1020  ssl_1021  ssl_1022  ssl_1023  \n",
      "0  1.210417  0.145564 -0.203183  0.308363 -1.006108  0.477833  \n",
      "1  1.386149 -0.865146 -0.025146  0.664296 -0.966043 -0.970576  \n",
      "2  0.895769 -0.774165 -0.138155  0.092459 -1.149930 -0.854394  \n",
      "3  1.105802  0.896047 -0.832068  0.055074 -0.788869  0.787627  \n",
      "4 -0.680709  0.574865 -0.695022  0.356909 -0.324964  0.789080  \n",
      "\n",
      "[5 rows x 1027 columns]\n",
      "=== Step2: モデル学習完了 ===\n",
      "\n",
      "=== Emotion Classification ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        67\n",
      "           1       0.94      0.91      0.92        64\n",
      "           2       0.97      0.89      0.93        64\n",
      "           3       0.97      0.88      0.93        77\n",
      "           4       0.94      0.97      0.96        68\n",
      "           5       0.85      0.91      0.88        64\n",
      "           6       0.97      0.97      0.97        64\n",
      "           7       0.90      0.97      0.93        64\n",
      "\n",
      "    accuracy                           0.93       532\n",
      "   macro avg       0.93      0.93      0.93       532\n",
      "weighted avg       0.93      0.93      0.93       532\n",
      "\n",
      "Emotion 混同行列保存 → results_ogvc_emo_int/confusion_emotion-bagus.png\n",
      "\n",
      "=== Intensity Regression ===\n",
      "MAE  : 0.6349\n",
      "MSE  : 0.6399\n",
      "RMSE : 0.7999\n",
      "予測結果 CSV 保存 → results_ogvc_emo_int/pred_emo-bunrui_int-kaiki-bagus.csv\n",
      "\n",
      "=== 完了：Emotion=分類 / Intensity=回帰 ===\n"
     ]
    }
   ],
   "source": [
    "# 強度を回帰で求める\n",
    "# 保存先；results_ogvc_emo_int/pred_emo-bunrui_int-kaiki-re2.csv\n",
    "\n",
    "# ======================================================\n",
    "# OGVC 完全版\n",
    "# Emotion : 分類（Logistic Regression）\n",
    "# Intensity : 回帰（Ridge Regression）\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット（Emotion 用）\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cmap=\"Blues\",\n",
    "        annot_kws={\"size\": 16}      # 数値を大きく\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# Step2: データ分割 & モデル学習\n",
    "# =========================================================\n",
    "def step2_train_model(df):\n",
    "    SPLIT_DIR = \"ogvc_split_data\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 特徴量\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    # ラベル\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int = df[\"intensity\"]  # ← 連続値のまま\n",
    "\n",
    "    # 分割（Emotion で stratify）\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test = train_test_split(\n",
    "        X, y_emo, y_int,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_emo\n",
    "    )\n",
    "\n",
    "    # 分割データ保存\n",
    "    train_df = df.loc[X_train.index]\n",
    "    test_df = df.loc[X_test.index]\n",
    "    train_df.to_csv(os.path.join(TRAIN_DIR, \"train_data-bagus.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(TEST_DIR, \"test_data-bagus.csv\"), index=False)\n",
    "\n",
    "    # ===== モデル =====\n",
    "    emo_model = LogisticRegression(max_iter=3000)\n",
    "    emo_model.fit(X_train, emo_train)\n",
    "\n",
    "    int_model = Ridge(alpha=1.0)\n",
    "    int_model.fit(X_train, int_train)\n",
    "\n",
    "    print(\"=== Step2: モデル学習完了 ===\")\n",
    "\n",
    "    return {\n",
    "        \"X_test\": X_test,\n",
    "        \"filename_test\": df.loc[X_test.index, \"filename\"] if \"filename\" in df.columns else None,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# Step3: 評価 & CSV出力\n",
    "# =========================================================\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    # 予測\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)  # 回帰（連続値）\n",
    "\n",
    "    # ========================\n",
    "    # Emotion（分類）\n",
    "    # ========================\n",
    "    print(\"\\n=== Emotion Classification ===\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion-bagus.png\")\n",
    "    plot_conf_matrix(\n",
    "        emo_test,\n",
    "        emo_pred,\n",
    "        list(EMOTION_LABELS.keys()),\n",
    "        \"OGVC Emotion Confusion Matrix\",\n",
    "        emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "    print(\"Emotion 混同行列保存 →\", emo_cm_path)\n",
    "\n",
    "    # ========================\n",
    "    # Intensity（回帰）\n",
    "    # ========================\n",
    "    mae = mean_absolute_error(int_test, int_pred)\n",
    "    mse = mean_squared_error(int_test, int_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(\"\\n=== Intensity Regression ===\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # 予測結果 CSV 保存\n",
    "    # ========================\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"intensity_error\": int_pred - int_test\n",
    "    })\n",
    "\n",
    "    pred_path = os.path.join(RESULT_DIR, \"pred_emo-bunrui_int-kaiki-bagus.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"予測結果 CSV 保存 →\", pred_path)\n",
    "\n",
    "# =========================================================\n",
    "# メイン処理\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"ogvc_wav2vec2_features_Bagus-jtes.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Emotion=分類 / Intensity=回帰 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7b41c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved emotion-labeled results to: results_ogvc_emo_int/pred_results_with_emotion_label-bagus.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の感情を数値からラベルに変換\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "pred_path = os.path.join(RESULT_DIR, \"pred_emo-bunrui_int-kaiki-bagus.csv\")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label-bagus.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 感情ラベル対応表\n",
    "# ================================\n",
    "EMOTION_ID2LABEL = {\n",
    "    0: \"JOY\",\n",
    "    1: \"ACC\",\n",
    "    2: \"FEA\",\n",
    "    3: \"SUR\",\n",
    "    4: \"SAD\",\n",
    "    5: \"DIS\",\n",
    "    6: \"ANG\",\n",
    "    7: \"ANT\"\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(pred_path)\n",
    "\n",
    "# ================================\n",
    "# 感情カテゴリのみラベル化\n",
    "# ================================\n",
    "df[\"emotion_true_label\"] = df[\"emotion_true\"].map(EMOTION_ID2LABEL)\n",
    "df[\"emotion_pred_label\"] = df[\"emotion_pred\"].map(EMOTION_ID2LABEL)\n",
    "\n",
    "# ※ intensity_true / intensity_pred はそのまま残す\n",
    "\n",
    "# ================================\n",
    "# 保存\n",
    "# ================================\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved emotion-labeled results to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b62c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Intensity Performance ===\n",
      "MAE  : 0.6349\n",
      "RMSE : 0.7999\n",
      "\n",
      "=== Emotion-wise Intensity Performance ===\n",
      "  emotion_true_label       MAE      RMSE  Count\n",
      "0                ACC  0.653925  0.810426     64\n",
      "1                ANG  0.667345  0.827965     64\n",
      "2                ANT  0.685597  0.868099     64\n",
      "3                DIS  0.692214  0.851128     64\n",
      "4                FEA  0.587891  0.751928     64\n",
      "5                JOY  0.584314  0.725720     67\n",
      "6                SAD  0.647716  0.862761     68\n",
      "7                SUR  0.574203  0.701042     77\n",
      "\n",
      "Saved emotion-wise MAE / RMSE to: results_ogvc_emo_int/eval_emotion_wise_intensity_mae_rmse-bagus.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果(pred_results_with_emotion_label.csv)を読み込んで，全体＋感情別 MAE / RMSEを出力\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "csv_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label-bagus.csv\"\n",
    ")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"eval_emotion_wise_intensity_mae_rmse-bagus.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ================================\n",
    "# 誤差計算（既存列を使用）\n",
    "# ================================\n",
    "# intensity_error = pred - true\n",
    "df[\"abs_error\"] = df[\"intensity_error\"].abs()\n",
    "df[\"sq_error\"] = df[\"intensity_error\"] ** 2\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ モデル全体の MAE / RMSE\n",
    "# ================================\n",
    "overall_mae = df[\"abs_error\"].mean()\n",
    "overall_rmse = np.sqrt(df[\"sq_error\"].mean())\n",
    "\n",
    "print(\"=== Overall Intensity Performance ===\")\n",
    "print(f\"MAE  : {overall_mae:.4f}\")\n",
    "print(f\"RMSE : {overall_rmse:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ 感情カテゴリ別 MAE / RMSE\n",
    "# ================================\n",
    "emotion_metrics = (\n",
    "    df.groupby(\"emotion_true_label\")\n",
    "      .agg(\n",
    "          MAE=(\"abs_error\", \"mean\"),\n",
    "          RMSE=(\"sq_error\", lambda x: np.sqrt(x.mean())),\n",
    "          Count=(\"abs_error\", \"count\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Emotion-wise Intensity Performance ===\")\n",
    "print(emotion_metrics)\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ 保存（論文・図表用）\n",
    "# ================================\n",
    "emotion_metrics.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved emotion-wise MAE / RMSE to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
