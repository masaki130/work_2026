{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a1307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2656 wav files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing WAV files: 100%|██████████| 2656/2656 [01:12<00:00, 36.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all results to VA_results_bulk/OGVC_VAD_last_hidden_bulk-re.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# OGVC\n",
    "# 量産版 + hidden_states 保存版\n",
    "# 感情次元ベクトル推定器で使用されている wav2vec2 の出力を\n",
    "# CSV (VA_results_bulk/OGVC_VAD_last_hidden_bulk-re.csv) に保存\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Wav2Vec2Processor\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2Model,\n",
    "    Wav2Vec2PreTrainedModel,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== 設定 =====\n",
    "ROOT_PATH = \"/autofs/diamond/share/corpus/OGVC/Vol2/Acted/wav\"\n",
    "OUTPUT_DIR = \"VA_results_bulk\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAMPLE_RATE = 16000\n",
    "MODEL_NAME = \"audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\"\n",
    "\n",
    "# Bagus と同じ正規表現\n",
    "FILENAME_PATTERN = re.compile(r\"^[A-Z0-9]+([A-Z]{3})(\\d)\\.wav$\", re.IGNORECASE)\n",
    "\n",
    "# ===== モデル定義 =====\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmotionModel(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = RegressionHead(config)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_values):\n",
    "        outputs = self.wav2vec2(input_values)\n",
    "        hidden_states = outputs[0]              # (B, T, D)\n",
    "        pooled = torch.mean(hidden_states, dim=1)\n",
    "        logits = self.classifier(pooled)\n",
    "        return pooled, logits\n",
    "\n",
    "\n",
    "# ===== モデルロード =====\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "model = EmotionModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ===== ユーティリティ =====\n",
    "def collect_wav_files(root: str):\n",
    "    \"\"\"wav 以下を再帰探索\"\"\"\n",
    "    return sorted([str(p) for p in Path(root).rglob(\"*.wav\")])\n",
    "\n",
    "\n",
    "def parse_filename_info(path: str):\n",
    "    \"\"\"\n",
    "    Bagus と同じ仕様\n",
    "    例: FOY0101ANT0.wav\n",
    "    -> utt_id=FOY0101, emotion=ANT, intensity=0\n",
    "    \"\"\"\n",
    "    fname = os.path.basename(path)\n",
    "    match = FILENAME_PATTERN.match(fname)\n",
    "    if match is None:\n",
    "        return None, None, None\n",
    "\n",
    "    emotion = match.group(1).upper()\n",
    "    intensity = int(match.group(2))\n",
    "\n",
    "    base = os.path.splitext(fname)[0]\n",
    "    utt_id = base[: -(len(emotion) + 1)]\n",
    "\n",
    "    return utt_id, emotion, intensity\n",
    "\n",
    "\n",
    "def load_audio(path, target_sr=SAMPLE_RATE):\n",
    "    wav, sr = sf.read(path)\n",
    "\n",
    "    if wav.ndim > 1:\n",
    "        wav = wav.mean(axis=1)\n",
    "\n",
    "    if sr != target_sr:\n",
    "        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "\n",
    "    return wav.astype(np.float32), sr\n",
    "\n",
    "\n",
    "def process_func(x: np.ndarray, sampling_rate: int):\n",
    "    y = processor(x, sampling_rate=sampling_rate)\n",
    "    y = torch.tensor(y[\"input_values\"][0]).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, logits = model(y)\n",
    "\n",
    "    return hidden.cpu().numpy()[0], logits.cpu().numpy()[0]\n",
    "\n",
    "\n",
    "# ===== メイン =====\n",
    "def extract_vad_bulk(root_dir=ROOT_PATH, output_dir=OUTPUT_DIR):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    wav_files = collect_wav_files(root_dir)\n",
    "    print(f\"Found {len(wav_files)} wav files\")\n",
    "\n",
    "    # hidden_size 自動取得\n",
    "    dummy_hidden, _ = process_func(np.zeros(SAMPLE_RATE), SAMPLE_RATE)\n",
    "    hidden_size = dummy_hidden.shape[0]\n",
    "\n",
    "    csv_path = os.path.join(output_dir, \"OGVC_VAD_last_hidden_bulk-re.csv\")\n",
    "\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as wf:\n",
    "        writer = csv.writer(wf)\n",
    "\n",
    "        header = [\n",
    "            \"utt_id\",\n",
    "            \"filename\",\n",
    "            \"valence\",\n",
    "            \"arousal\",\n",
    "            \"dominance\",\n",
    "            \"intensity\",\n",
    "            \"emotion\",\n",
    "        ] + [f\"h_{i}\" for i in range(hidden_size)]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for path in tqdm(wav_files, desc=\"Processing WAV files\"):\n",
    "            utt_id, emo, inten = parse_filename_info(path)\n",
    "            if utt_id is None:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                wav, sr = load_audio(path)\n",
    "                hidden_vec, vad = process_func(wav, sr)\n",
    "\n",
    "                row = [\n",
    "                    utt_id,\n",
    "                    os.path.basename(path),\n",
    "                    float(vad[2]),   # valence\n",
    "                    float(vad[0]),   # arousal\n",
    "                    float(vad[1]),   # dominance\n",
    "                    inten,\n",
    "                    emo,\n",
    "                ] + hidden_vec.tolist()\n",
    "\n",
    "                writer.writerow(row)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "    print(f\"Saved all results to {csv_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_vad_bulk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb49435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "    utt_id         filename   valence   arousal  dominance  intensity emotion  \\\n",
      "0  FOY0101  FOY0101ANT0.wav  0.343053  0.333032   0.417036          0     ANT   \n",
      "1  FOY0101  FOY0101ANT1.wav  0.358071  0.425703   0.479033          1     ANT   \n",
      "2  FOY0101  FOY0101ANT2.wav  0.449238  0.607365   0.616360          2     ANT   \n",
      "3  FOY0101  FOY0101ANT3.wav  0.427220  0.620275   0.616097          3     ANT   \n",
      "4  FOY0104  FOY0104FEA0.wav  0.337510  0.301136   0.398823          0     FEA   \n",
      "\n",
      "        h_0       h_1       h_2  ...    h_1014    h_1015    h_1016    h_1017  \\\n",
      "0 -0.007525  0.006666 -0.010108  ...  0.003701  0.011701 -0.019870  0.007911   \n",
      "1 -0.007513  0.006847 -0.007410  ...  0.003669  0.011756 -0.013553  0.008053   \n",
      "2 -0.007452  0.006693 -0.007730  ...  0.003666  0.011478 -0.031439  0.008050   \n",
      "3 -0.007458  0.006260 -0.007765  ...  0.003586  0.011238 -0.018411  0.008144   \n",
      "4 -0.007517  0.005590 -0.009640  ...  0.004394  0.011929 -0.033647  0.008054   \n",
      "\n",
      "     h_1018    h_1019    h_1020    h_1021    h_1022    h_1023  \n",
      "0 -0.034503  0.112575  0.130890  0.007408  0.006509  0.004706  \n",
      "1 -0.036534  0.147744  0.150029  0.007322  0.006943  0.005024  \n",
      "2 -0.025274  0.116805  0.190999  0.007313  0.008009  0.005188  \n",
      "3 -0.027275  0.110437  0.208032  0.007359  0.007842  0.005595  \n",
      "4 -0.007207  0.049466  0.104428  0.007225  0.007167  0.004856  \n",
      "\n",
      "[5 rows x 1031 columns]\n",
      "=== Step2: モデル学習完了 ===\n",
      "\n",
      "=== Step3: 評価 ===\n",
      "\n",
      "Emotion Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62        67\n",
      "           1       0.62      0.55      0.58        64\n",
      "           2       0.73      0.55      0.62        64\n",
      "           3       0.62      0.69      0.65        77\n",
      "           4       0.62      0.65      0.63        68\n",
      "           5       0.53      0.62      0.57        64\n",
      "           6       0.57      0.64      0.60        64\n",
      "           7       0.59      0.52      0.55        64\n",
      "\n",
      "    accuracy                           0.61       532\n",
      "   macro avg       0.61      0.60      0.61       532\n",
      "weighted avg       0.61      0.61      0.61       532\n",
      "\n",
      "\n",
      "Intensity Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.80      0.76       144\n",
      "           1       0.58      0.54      0.56       138\n",
      "           2       0.46      0.41      0.43       132\n",
      "           3       0.63      0.67      0.65       118\n",
      "\n",
      "    accuracy                           0.61       532\n",
      "   macro avg       0.60      0.61      0.60       532\n",
      "weighted avg       0.60      0.61      0.60       532\n",
      "\n",
      "\n",
      "予測結果を保存しました → results_ogvc_emo_int/prediction_results-re1.csv\n",
      "混同行列保存 → results_ogvc_emo_int/confusion_emotion-re1.png\n",
      "混同行列保存 → results_ogvc_emo_int/confusion_intensity-re1.png\n",
      "\n",
      "=== 完了：Step1 → Step2 → Step3 ===\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# OGVC 版：ロジスティック回帰で Emotion / Intensity を分類\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\", annot_kws={\"size\": 16})\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# Step2: データ分割 & モデル学習\n",
    "# =========================================================\n",
    "def step2_train_model(df):\n",
    "    SPLIT_DIR = \"ogvc_split_data\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int = df[\"intensity\"]\n",
    "\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test = train_test_split(\n",
    "        X, y_emo, y_int, test_size=0.2, random_state=42, stratify=y_emo\n",
    "    )\n",
    "\n",
    "    train_df = df.loc[X_train.index]\n",
    "    test_df = df.loc[X_test.index]\n",
    "    train_df.to_csv(os.path.join(TRAIN_DIR, \"train_data-re1.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(TEST_DIR, \"test_data-re1.csv\"), index=False)\n",
    "\n",
    "    emo_model = LogisticRegression(max_iter=3000).fit(X_train, emo_train)\n",
    "    int_model = LogisticRegression(max_iter=3000).fit(X_train, int_train)\n",
    "\n",
    "    print(\"=== Step2: モデル学習完了 ===\")\n",
    "\n",
    "    return {\n",
    "        \"X_test\": X_test,\n",
    "        \"filename_test\": df.loc[X_test.index, \"filename\"] if \"filename\" in df.columns else None,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# Step3: 評価 & CSV出力\n",
    "# =========================================================\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Step3: 評価 ===\")\n",
    "    print(\"\\nEmotion Classification Report\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "    print(\"\\nIntensity Classification Report\")\n",
    "    print(classification_report(int_test, int_pred))\n",
    "\n",
    "    # 予測結果 CSV 保存\n",
    "    emotion_correct = [\"〇\" if t == p else \"×\" for t, p in zip(emo_test, emo_pred)]\n",
    "    intensity_correct = [\"〇\" if t == p else \"×\" for t, p in zip(int_test, int_pred)]\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"emotion_correct\": emotion_correct,\n",
    "        \"intensity_correct\": intensity_correct\n",
    "    })\n",
    "    pred_path = os.path.join(RESULT_DIR, \"prediction_results-re1.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"\\n予測結果を保存しました →\", pred_path)\n",
    "\n",
    "    # 混同行列\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion-re1.png\")\n",
    "    int_cm_path = os.path.join(RESULT_DIR, \"confusion_intensity-re1.png\")\n",
    "\n",
    "    plot_conf_matrix(\n",
    "        emo_test, emo_pred, list(EMOTION_LABELS.keys()),\n",
    "        \" OGVC Emotion Confusion Matrix\", emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "\n",
    "    plot_conf_matrix(   # 3を追加\n",
    "        int_test, int_pred, [\"0\", \"1\", \"2\", \"3\"],\n",
    "        \"OGVC Intensity Confusion Matrix\", int_cm_path\n",
    "    )\n",
    "\n",
    "    print(\"混同行列保存 →\", emo_cm_path)\n",
    "    print(\"混同行列保存 →\", int_cm_path)\n",
    "\n",
    "# =========================================================\n",
    "# メイン処理\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"VA_results_bulk/OGVC_VAD_last_hidden_bulk-re.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Step1 → Step2 → Step3 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b04b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step1: データ読み込み完了 ===\n",
      "    utt_id         filename   valence   arousal  dominance  intensity emotion  \\\n",
      "0  FOY0101  FOY0101ANT0.wav  0.343053  0.333032   0.417036          0     ANT   \n",
      "1  FOY0101  FOY0101ANT1.wav  0.358071  0.425703   0.479033          1     ANT   \n",
      "2  FOY0101  FOY0101ANT2.wav  0.449238  0.607365   0.616360          2     ANT   \n",
      "3  FOY0101  FOY0101ANT3.wav  0.427220  0.620275   0.616097          3     ANT   \n",
      "4  FOY0104  FOY0104FEA0.wav  0.337510  0.301136   0.398823          0     FEA   \n",
      "\n",
      "        h_0       h_1       h_2  ...    h_1014    h_1015    h_1016    h_1017  \\\n",
      "0 -0.007525  0.006666 -0.010108  ...  0.003701  0.011701 -0.019870  0.007911   \n",
      "1 -0.007513  0.006847 -0.007410  ...  0.003669  0.011756 -0.013553  0.008053   \n",
      "2 -0.007452  0.006693 -0.007730  ...  0.003666  0.011478 -0.031439  0.008050   \n",
      "3 -0.007458  0.006260 -0.007765  ...  0.003586  0.011238 -0.018411  0.008144   \n",
      "4 -0.007517  0.005590 -0.009640  ...  0.004394  0.011929 -0.033647  0.008054   \n",
      "\n",
      "     h_1018    h_1019    h_1020    h_1021    h_1022    h_1023  \n",
      "0 -0.034503  0.112575  0.130890  0.007408  0.006509  0.004706  \n",
      "1 -0.036534  0.147744  0.150029  0.007322  0.006943  0.005024  \n",
      "2 -0.025274  0.116805  0.190999  0.007313  0.008009  0.005188  \n",
      "3 -0.027275  0.110437  0.208032  0.007359  0.007842  0.005595  \n",
      "4 -0.007207  0.049466  0.104428  0.007225  0.007167  0.004856  \n",
      "\n",
      "[5 rows x 1031 columns]\n",
      "=== Step2: モデル学習完了 ===\n",
      "\n",
      "=== Emotion Classification ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62        67\n",
      "           1       0.62      0.55      0.58        64\n",
      "           2       0.73      0.55      0.62        64\n",
      "           3       0.62      0.69      0.65        77\n",
      "           4       0.62      0.65      0.63        68\n",
      "           5       0.53      0.62      0.57        64\n",
      "           6       0.57      0.64      0.60        64\n",
      "           7       0.59      0.52      0.55        64\n",
      "\n",
      "    accuracy                           0.61       532\n",
      "   macro avg       0.61      0.60      0.61       532\n",
      "weighted avg       0.61      0.61      0.61       532\n",
      "\n",
      "Emotion 混同行列保存 → results_ogvc_emo_int/confusion_emotion-re2.png\n",
      "\n",
      "=== Intensity Regression ===\n",
      "MAE  : 0.4987\n",
      "MSE  : 0.3962\n",
      "RMSE : 0.6294\n",
      "予測結果 CSV 保存 → results_ogvc_emo_int/pred_emo-bunrui_int-kaiki-re2.csv\n",
      "\n",
      "=== 完了：Emotion=分類 / Intensity=回帰 ===\n"
     ]
    }
   ],
   "source": [
    "# 強度を回帰で求める\n",
    "# 保存先；results_ogvc_emo_int/pred_emo-bunrui_int-kaiki-re2.csv\n",
    "\n",
    "# ======================================================\n",
    "# OGVC 完全版\n",
    "# Emotion : 分類（Logistic Regression）\n",
    "# Intensity : 回帰（Ridge Regression）\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "EMOTION_LABELS = {\n",
    "    \"JOY\": 0, \"ACC\": 1, \"FEA\": 2, \"SUR\": 3,\n",
    "    \"SAD\": 4, \"DIS\": 5, \"ANG\": 6, \"ANT\": 7,\n",
    "    \"NEU\": 8, \"OTH\": 9\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 混同行列プロット（Emotion 用）\n",
    "# =========================================================\n",
    "def plot_conf_matrix(true, pred, labels, title, save_path, exclude_labels=None):\n",
    "    cm = confusion_matrix(true, pred, labels=range(len(labels)))\n",
    "\n",
    "    if exclude_labels is not None:\n",
    "        exclude_idx = [labels.index(l) for l in exclude_labels]\n",
    "        cm = np.delete(cm, exclude_idx, axis=0)\n",
    "        cm = np.delete(cm, exclude_idx, axis=1)\n",
    "        labels = [l for l in labels if l not in exclude_labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cmap=\"Blues\",\n",
    "        annot_kws={\"size\": 16}      # 数値を大きく\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# =========================================================\n",
    "# Step1: データ読み込み\n",
    "# =========================================================\n",
    "def step1_load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"=== Step1: データ読み込み完了 ===\")\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# =========================================================\n",
    "# Step2: データ分割 & モデル学習\n",
    "# =========================================================\n",
    "def step2_train_model(df):\n",
    "    SPLIT_DIR = \"ogvc_split_data\"\n",
    "    TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "    TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 特徴量\n",
    "    feature_df = df.drop(columns=[\"emotion\", \"intensity\"])\n",
    "    numeric_cols = feature_df.select_dtypes(include=[np.number]).columns\n",
    "    X = feature_df[numeric_cols]\n",
    "\n",
    "    # ラベル\n",
    "    y_emo = df[\"emotion\"].map(EMOTION_LABELS)\n",
    "    y_int = df[\"intensity\"]  # ← 連続値のまま\n",
    "\n",
    "    # 分割（Emotion で stratify）\n",
    "    X_train, X_test, emo_train, emo_test, int_train, int_test = train_test_split(\n",
    "        X, y_emo, y_int,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_emo\n",
    "    )\n",
    "\n",
    "    # 分割データ保存\n",
    "    train_df = df.loc[X_train.index]\n",
    "    test_df = df.loc[X_test.index]\n",
    "    train_df.to_csv(os.path.join(TRAIN_DIR, \"train_data-re2.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(TEST_DIR, \"test_data-re2.csv\"), index=False)\n",
    "\n",
    "    # ===== モデル =====\n",
    "    emo_model = LogisticRegression(max_iter=3000)\n",
    "    emo_model.fit(X_train, emo_train)\n",
    "\n",
    "    int_model = Ridge(alpha=1.0)\n",
    "    int_model.fit(X_train, int_train)\n",
    "\n",
    "    print(\"=== Step2: モデル学習完了 ===\")\n",
    "\n",
    "    return {\n",
    "        \"X_test\": X_test,\n",
    "        \"filename_test\": df.loc[X_test.index, \"filename\"] if \"filename\" in df.columns else None,\n",
    "        \"emo_test\": emo_test,\n",
    "        \"int_test\": int_test,\n",
    "        \"emo_model\": emo_model,\n",
    "        \"int_model\": int_model\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# Step3: 評価 & CSV出力\n",
    "# =========================================================\n",
    "def step3_evaluate(data):\n",
    "    X_test = data[\"X_test\"]\n",
    "    filename_test = data[\"filename_test\"]\n",
    "    emo_test = data[\"emo_test\"]\n",
    "    int_test = data[\"int_test\"]\n",
    "    emo_model = data[\"emo_model\"]\n",
    "    int_model = data[\"int_model\"]\n",
    "\n",
    "    # 予測\n",
    "    emo_pred = emo_model.predict(X_test)\n",
    "    int_pred = int_model.predict(X_test)  # 回帰（連続値）\n",
    "\n",
    "    # ========================\n",
    "    # Emotion（分類）\n",
    "    # ========================\n",
    "    print(\"\\n=== Emotion Classification ===\")\n",
    "    print(classification_report(emo_test, emo_pred))\n",
    "\n",
    "    emo_cm_path = os.path.join(RESULT_DIR, \"confusion_emotion-re2.png\")\n",
    "    plot_conf_matrix(\n",
    "        emo_test,\n",
    "        emo_pred,\n",
    "        list(EMOTION_LABELS.keys()),\n",
    "        \"OGVC Emotion Confusion Matrix\",\n",
    "        emo_cm_path,\n",
    "        exclude_labels=[\"NEU\", \"OTH\"]\n",
    "    )\n",
    "    print(\"Emotion 混同行列保存 →\", emo_cm_path)\n",
    "\n",
    "    # ========================\n",
    "    # Intensity（回帰）\n",
    "    # ========================\n",
    "    mae = mean_absolute_error(int_test, int_pred)\n",
    "    mse = mean_squared_error(int_test, int_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(\"\\n=== Intensity Regression ===\")\n",
    "    print(f\"MAE  : {mae:.4f}\")\n",
    "    print(f\"MSE  : {mse:.4f}\")\n",
    "    print(f\"RMSE : {rmse:.4f}\")\n",
    "\n",
    "    # ========================\n",
    "    # 予測結果 CSV 保存\n",
    "    # ========================\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"filename\": filename_test,\n",
    "        \"emotion_true\": emo_test,\n",
    "        \"emotion_pred\": emo_pred,\n",
    "        \"intensity_true\": int_test,\n",
    "        \"intensity_pred\": int_pred,\n",
    "        \"intensity_error\": int_pred - int_test\n",
    "    })\n",
    "\n",
    "    pred_path = os.path.join(RESULT_DIR, \"pred_emo-bunrui_int-kaiki-re2.csv\")\n",
    "    pred_df.to_csv(pred_path, index=False)\n",
    "    print(\"予測結果 CSV 保存 →\", pred_path)\n",
    "\n",
    "# =========================================================\n",
    "# メイン処理\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    df = step1_load_data(\"VA_results_bulk/OGVC_VAD_last_hidden_bulk-re.csv\")\n",
    "    data = step2_train_model(df)\n",
    "    step3_evaluate(data)\n",
    "    print(\"\\n=== 完了：Emotion=分類 / Intensity=回帰 ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a727d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved emotion-labeled results to: results_ogvc_emo_int/pred_results_with_emotion_label-re2.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の感情を数値からラベルに変換\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "pred_path = os.path.join(RESULT_DIR, \"pred_emo-bunrui_int-kaiki-re2.csv\")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label-re2.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 感情ラベル対応表\n",
    "# ================================\n",
    "EMOTION_ID2LABEL = {\n",
    "    0: \"JOY\",\n",
    "    1: \"ACC\",\n",
    "    2: \"FEA\",\n",
    "    3: \"SUR\",\n",
    "    4: \"SAD\",\n",
    "    5: \"DIS\",\n",
    "    6: \"ANG\",\n",
    "    7: \"ANT\"\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(pred_path)\n",
    "\n",
    "# ================================\n",
    "# 感情カテゴリのみラベル化\n",
    "# ================================\n",
    "df[\"emotion_true_label\"] = df[\"emotion_true\"].map(EMOTION_ID2LABEL)\n",
    "df[\"emotion_pred_label\"] = df[\"emotion_pred\"].map(EMOTION_ID2LABEL)\n",
    "\n",
    "# ※ intensity_true / intensity_pred はそのまま残す\n",
    "\n",
    "# ================================\n",
    "# 保存\n",
    "# ================================\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Saved emotion-labeled results to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ecbcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Intensity Performance ===\n",
      "MAE  : 0.4987\n",
      "RMSE : 0.6294\n",
      "\n",
      "=== Emotion-wise Intensity Performance ===\n",
      "  emotion_true_label       MAE      RMSE  Count\n",
      "0                ACC  0.591620  0.730829     64\n",
      "1                ANG  0.489957  0.639905     64\n",
      "2                ANT  0.521203  0.641177     64\n",
      "3                DIS  0.531545  0.687275     64\n",
      "4                FEA  0.442996  0.553311     64\n",
      "5                JOY  0.386811  0.471833     67\n",
      "6                SAD  0.562957  0.696239     68\n",
      "7                SUR  0.469864  0.585042     77\n",
      "\n",
      "Saved emotion-wise MAE / RMSE to: results_ogvc_emo_int/eval_emotion_wise_intensity_mae_rmse-re2.csv\n"
     ]
    }
   ],
   "source": [
    "# 予測結果(pred_results_with_emotion_label.csv)を読み込んで，全体＋感情別 MAE / RMSEを出力\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 設定\n",
    "# ================================\n",
    "RESULT_DIR = \"results_ogvc_emo_int\"\n",
    "csv_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"pred_results_with_emotion_label-re2.csv\"\n",
    ")\n",
    "\n",
    "out_path = os.path.join(\n",
    "    RESULT_DIR,\n",
    "    \"eval_emotion_wise_intensity_mae_rmse-re2.csv\"\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# CSV読み込み\n",
    "# ================================\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ================================\n",
    "# 誤差計算（既存列を使用）\n",
    "# ================================\n",
    "# intensity_error = pred - true\n",
    "df[\"abs_error\"] = df[\"intensity_error\"].abs()\n",
    "df[\"sq_error\"] = df[\"intensity_error\"] ** 2\n",
    "\n",
    "# ================================\n",
    "# 1️⃣ モデル全体の MAE / RMSE\n",
    "# ================================\n",
    "overall_mae = df[\"abs_error\"].mean()\n",
    "overall_rmse = np.sqrt(df[\"sq_error\"].mean())\n",
    "\n",
    "print(\"=== Overall Intensity Performance ===\")\n",
    "print(f\"MAE  : {overall_mae:.4f}\")\n",
    "print(f\"RMSE : {overall_rmse:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 2️⃣ 感情カテゴリ別 MAE / RMSE\n",
    "# ================================\n",
    "emotion_metrics = (\n",
    "    df.groupby(\"emotion_true_label\")\n",
    "      .agg(\n",
    "          MAE=(\"abs_error\", \"mean\"),\n",
    "          RMSE=(\"sq_error\", lambda x: np.sqrt(x.mean())),\n",
    "          Count=(\"abs_error\", \"count\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\n=== Emotion-wise Intensity Performance ===\")\n",
    "print(emotion_metrics)\n",
    "\n",
    "# ================================\n",
    "# 3️⃣ 保存（論文・図表用）\n",
    "# ================================\n",
    "emotion_metrics.to_csv(out_path, index=False)\n",
    "print(f\"\\nSaved emotion-wise MAE / RMSE to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
